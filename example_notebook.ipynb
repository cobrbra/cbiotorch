{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `cbiotorch`: an example workflow\n",
    "In this notebook we'll use some of the key functionality provided by the `cbiotorch` package to develop a simple pytorch prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is `cbiotorch` for?\n",
    "CBioPortal is a fantastic resource of curated cancer genomics datasets. Mutation profiles for samples from cancer patients provide excellent resources for developing predictive modelling of clinical cancer outcomes, but require substantial pre-processing and reconciliation. This includes\n",
    "* reconciliation of data across multiple studies, including the use of varying gene panels;\n",
    "* separation/pooling of different cancer types; \n",
    "* identification and cleaning of clinical outcomes; and\n",
    "* data processing for ease of use with ML libraries.\n",
    "\n",
    "This package achieves the stated goals and prepared CBioPortal datasets for use with PyTorch, a popular and flexible library for applying ML methods. The following tutorial demonstrates a simple application of that workflow by loading two "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading CBioPortal datasets with `cbiotorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off we need some studies. In `cbiotorch`, these are stored in the `MutationDataset` class. We can specify which of these we use by providing a list of study identifiers. Here we'll use two studies, \"msk_impact_2017\" and \"tmb_mskcc_2018\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cbiotorch:Searching for mutations from File for msk_impact_2017.\n",
      "/Users/jbradley/Documents/turing/cbiotorch/cbiotorch/get.py:63: DtypeWarning: Columns (2,18,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mutations_df = pd.read_csv(join(self.from_dir, study_id, \"mutations.csv\"))\n",
      "INFO:cbiotorch:Read mutations\n",
      "INFO:cbiotorch:Read samples\n",
      "INFO:cbiotorch:Read sample/genes\n",
      "INFO:cbiotorch:Searching for mutations from File for tmb_mskcc_2018.\n",
      "INFO:cbiotorch:Read mutations\n",
      "INFO:cbiotorch:Read samples\n",
      "INFO:cbiotorch:Read sample/genes\n"
     ]
    }
   ],
   "source": [
    "from cbiotorch.data import MutationDataset\n",
    "\n",
    "msk_mutations = MutationDataset(study_id=[\"msk_impact_2017\", \"tmb_mskcc_2018\"])\n",
    "msk_mutations.write(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this takes a little while to run. Because we don't have the datasets loaded, `cbiotorch` has to query CBioPortal's REST API. We can write the datasets to file using the `.write()` method. Once we've run this, in future `MutationDataset` will look for the saved files, and so this will be much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem when combining multiple datasets (and even sometimes within a single dataset) is that different gene panels are used to profile different samples. This can be a problem for prediction, as it is not necessarily possible to distinguish which genes were unmutated and which were not profiled. In this case, some samples were profiled using the \"IMPACT341\" panel and some using the \"IMPACT410\" panel. What `MutationDataset` does is automatically generate a \"maximal valid gene panel\", i.e pooling all genes which were profiled in all samples across the data. We can see below that this is 341 genes long (i.e. simply the IMPACT341 panel, which is a subset of IMPACT410), and look at some of the genes contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of maximum viable panel: 341\n",
      "Some genes in that panel: KEAP1, IFNGR1, DAXX, BARD1, CHEK1.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of maximum viable panel: {len(msk_mutations.auto_gene_panel)}\")\n",
    "print(f\"Some genes in that panel: {', '.join(msk_mutations.auto_gene_panel[:5])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing data: lung cancer example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to properly use mutation datasets, we have to apply various processing steps. These can occur at various stages in a workflow, but we achieve all of these using *transforms*. Transforms in `cbiotorch` come (unsurprisingly) from the `transforms` module, which is designed to behave similarly to the `torchvision` module of the same name. Broadly speaking, there are two stages at which we might employ them: at dataset initiation, where they are applied to the entire dataset as it is assembled (i.e. before it is written to file in the example use of `MutationDataset` above), and those applied only to individual samples during data loading in model training. We'll discuss more about the latter type of transform later on, and for now focus on situations where we want to apply a pre-preocessing transform. Here we'll assume we only want to work with lung cancer samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting clinical outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to compare between these two studies what clinical features are available. We can do this using the `ClinicalDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbiotorch.data import ClinicalDataset\n",
    "from cbiotorch.transform import ToTensor, FilterSelect\n",
    "from cbiotorch.write import PandasWriter\n",
    "\n",
    "msk_clinical = ClinicalDataset(\n",
    "    study_id=[\"tmb_mskcc_2018\", \"msk_impact_2017\"],\n",
    "    pre_transform=FilterSelect(),\n",
    ")\n",
    "\n",
    "msk_clinical.set_writer(PandasWriter(replace=True))\n",
    "msk_clinical.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbiotorch.transform import ToSparseCountTensor\n",
    "\n",
    "transform_sparse = ToSparseCountTensor(\n",
    "    dims=[\"hugoGeneSymbol\", \"variantType\"], dim_refs=msk_mutations.auto_dim_refs\n",
    ")\n",
    "msk_mutations.add_transform(transform_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5106505292700980056"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash((msk_clinical_new.__class__, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.turing_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b8bff0248736755362b0b04f8fc4728f16af48b09cef1f60d19e4c72b0590cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
