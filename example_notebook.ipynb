{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example `cbiotorch` workflow\n",
    "In this notebook we'll use some of the key functionality provided by the `cbiotorch` package to develop a simple pytorch prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is `cbiotorch` for?\n",
    "CBioPortal is a fantastic resource of curated cancer genomics datasets. Mutation profiles for samples from cancer patients provide excellent resources for developing predictive modelling of clinical cancer outcomes, but require substantial pre-processing and reconciliation. This includes\n",
    "* reconciliation of data across multiple studies, including the use of varying gene panels;\n",
    "* separation/pooling of different cancer types; \n",
    "* identification and cleaning of clinical outcomes; and\n",
    "* data processing for ease of use with ML libraries.\n",
    "\n",
    "This package achieves the stated goals and prepared CBioPortal datasets for use with PyTorch, a popular and flexible library for applying ML methods. The following tutorial demonstrates a simple application of that workflow by loading two "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading CBioPortal datasets with `cbiotorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off we need some studies. In `cbiotorch`, these are stored in the `MutationDataset` class. We can specify which of these we use by providing a list of study identifiers. Here we'll use two studies, \"msk_impact_2017\" and \"tmb_mskcc_2018\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbiotorch.data import MutationDataset\n",
    "\n",
    "msk_mutations = MutationDataset(study_id=[\"msk_impact_2017\", \"tmb_mskcc_2018\"])\n",
    "msk_mutations.write(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this takes a little while to run. Because we don't have the datasets loaded, `cbiotorch` has to query CBioPortal's REST API. We can write the datasets to file using the `.write()` method. Once we've run this, in future `MutationDataset` will look for the saved files, and so this will be much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem when combining multiple datasets (and even sometimes within a single dataset) is that different gene panels are used to profile different samples. This can be a problem for prediction, as it is not necessarily possible to distinguish which genes were unmutated and which were not profiled. In this case, some samples were profiled using the \"IMPACT341\" panel and some using the \"IMPACT410\" panel. What `MutationDataset` does is automatically generate a \"maximal valid gene panel\", i.e pooling all genes which were profiled in all samples across the data. We can see below that this is 341 genes long (i.e. simply the IMPACT341 panel, which is a subset of IMPACT410), and look at some of the genes contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of maximum viable panel: 341\n",
      "Some genes in that panel: KEAP1, IFNGR1, DAXX, BARD1, CHEK1.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of maximum viable panel: {len(msk_mutations.auto_gene_panel)}\")\n",
    "print(f\"Some genes in that panel: {', '.join(msk_mutations.auto_gene_panel[:5])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing data: lung cancer example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to properly use mutation datasets, we have to apply various processing steps. These can occur at various stages in a workflow, but we achieve all of these using *transforms*. Transforms in `cbiotorch` come (unsurprisingly) from the `transforms` module, which is designed to behave similarly to the `torchvision` module of the same name. Broadly speaking, there are two stages at which we might employ them: at dataset initiating, where they are applied to the entire dataset as it is assembled (i.e. before it is written to file in the example use of `MutationDataset` above), and those applied only to individual samples during data loading in model training. We'll discuss more about the latter type of transform later on, and for now focus on situations where we want to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting clinical outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbiotorch.transforms import ToSparseCountTensor\n",
    "\n",
    "transform_sparse = ToSparseCountTensor(\n",
    "    dims=[\"hugoGeneSymbol\", \"variantType\"], dim_refs=msk_mutations.auto_dim_refs()\n",
    ")\n",
    "msk_mutations.add_transform(transform_sparse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.turing_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b8bff0248736755362b0b04f8fc4728f16af48b09cef1f60d19e4c72b0590cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
